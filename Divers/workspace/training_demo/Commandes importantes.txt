//TF2 Model Zoo
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md



//Convert raw COCO dataset to TFRecord for object_detection
python create_coco_tf_record.py --logtostderr \
      --train_image_dir="${TRAIN_IMAGE_DIR}" \
      --val_image_dir="${VAL_IMAGE_DIR}" \
      --test_image_dir="${TEST_IMAGE_DIR}" \
      --train_annotations_file="${TRAIN_ANNOTATIONS_FILE}" \
      --val_annotations_file="${VAL_ANNOTATIONS_FILE}" \
      --output_dir="${OUTPUT_DIR}"

python create_coco_tf_record.py --data_dir=. --set=train --output_path=output --shuffle_imgs=True





//Lancer le training
python model_main_tf2.py --model_dir=models/my_ssd_mobilenet_v2_fpnlite_320x320 --pipeline_config_path=models/my_ssd_mobilenet_v2_fpnlite_320x320/pipeline.config
python model_main_tf2.py --model_dir=models/my_ssd_mobilenet_v2_320x320_Frozen --pipeline_config_path=models/my_ssd_mobilenet_v2_320x320_Frozen/pipeline.config

//Exporter un model entraine pour inferance
python .\exporter_main_v2.py --input_type image_tensor --pipeline_config_path .\models\my_ssd_mobilenet_v2_fpnlite_320x320\pipeline.config --trained_checkpoint_dir .\models\my_ssd_mobilenet_v2_fpnlite_320x320\ --output_directory .\exported-models\my_model
python .\exporter_main_v2.py --input_type image_tensor --pipeline_config_path .\models\my_ssd_mobilenet_v2_320x320_Frozen\pipeline.config --trained_checkpoint_dir .\models\my_ssd_mobilenet_v2_320x320_Frozen\ --output_directory .\exported-models\my_model_Frozen
python .\exporter_main_v2.py --input_type image_tensor --pipeline_config_path .\models\my_ssd_mobilenet_v2_320x320pretrain\pipeline.config --trained_checkpoint_dir .\models\my_ssd_mobilenet_v2_320x320pretrain\ --output_directory .\exported-models\my_modelpretrain

//Exporting the model to a frozen graph (do not use)
python export_tflite_ssd_graph.py --pipeline_config_path models/my_ssd_mobilenet_v2_fpnlite_320x320/pipeline.config --trained_checkpoint_prefix models/my_ssd_mobilenet_v2_fpnlite_320x320/  --output_directory exported-models --add_postprocessing_op=true

//script to generate a TFLite-friendly intermediate SavedModel. This will then be passed to the TensorFlow Lite Converter for generating the final model.
python export_tflite_graph_tf2.py --pipeline_config_path models/my_ssd_mobilenet_v2_fpnlite_320x320/pipeline.config --trained_checkpoint_dir models/my_ssd_mobilenet_v2_fpnlite_320x320/ --output_directory exported-models/my_model/tflite
python export_tflite_graph_tf2.py --pipeline_config_path models/my_ssd_mobilenet_v2_320x320_Frozen/pipeline.config --trained_checkpoint_dir models/my_ssd_mobilenet_v2_320x320_Frozen/ --output_directory exported-models/my_model_Frozen/tflite
python export_tflite_graph_tf2.py --pipeline_config_path models/my_ssd_mobilenet_v2_320x320pretrain/pipeline.config --trained_checkpoint_dir models/my_ssd_mobilenet_v2_320x320pretrain/checkpoint --output_directory exported-models/my_modelpretrain/tflite

//Convertir le graph tflite au format .tflite
tflite_convert --output_file=exported-models/my_model/tflite/saved_model/saved_model.tflite --saved_model_dir=exported-models/my_model/tflite/saved_model --input_arrays=input --output_arrays=output --inference_type=QUANTIZED_UINT8
tflite_convert --output_file=exported-models/my_model_8bit/saved_model.tflite --saved_model_dir=exported-models/my_model_8bit/saved_model --input_arrays=input --output_arrays=output --inference_type=QUANTIZED_UINT8
tflite_convert --output_file=exported-models/my_model_Frozen/tflite/saved_model.tflite --saved_model_dir=exported-models/my_model_Frozen/tflite/saved_model --input_arrays=input --output_arrays=output --inference_type=QUANTIZED_UINT8
tflite_convert --output_file=exported-models/my_modelpretrain/tflite/saved_model.tflite --saved_model_dir=exported-models/my_modelpretrain/tflite/saved_model --input_arrays=input --output_arrays=output --inference_type=QUANTIZED_UINT8

//Tester le model sur quelques images (depuis l'emplacement "training_demo")
python .\plot_object_detection_saved_model.py
python .\plot_object_detection_saved_model_Frozen.py

//Activer tensorboard pour visualiser l'avancement du training
//Ouvrir unenouvelle fenetre anaconda
//Puis executer lescommandes suivantes:
(base) C:\Users\valen>conda activate tensorflow
(tensorflow) C:\Users\valen>cd ../../Conda/Tensorflow/workspace/training_demo
(tensorflow) C:\Conda\Tensorflow\workspace\training_demo>tensorboard --logdir=models/my_ssd_mobilenet_v2_fpnlite_320x320
2021-10-16 04:29:55.682672: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
TensorBoard 2.7.0 at http://localhost:6006/ (Press CTRL+C to quit)



//Post quantization of model
python Quantification_post_training3.py